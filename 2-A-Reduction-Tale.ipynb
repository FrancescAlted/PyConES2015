{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Reduction Tale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Objectives:\n",
    "> * Compare operations taking place in different data containers\n",
    "> * Compare sizes for these data containers\n",
    "> * Help deciding when it is best to use a container or another"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's suppose that we are going to need reductions a lot and we want to choose the best container for performing them.  First, let's start by activating our MemWatcher agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [1] used 0.020 MiB RAM in 0.001s, peaked 0.000 MiB above current, total RAM usage 29.809 MiB\n"
     ]
    }
   ],
   "source": [
    "from ipython_memwatcher import MemWatcher\n",
    "mw = MemWatcher()\n",
    "mw.start_watching_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and choose a different container for the data that we want to reduce, starting with a list:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [2] used 33.180 MiB RAM in 0.094s, peaked 0.000 MiB above current, total RAM usage 62.988 MiB\n"
     ]
    }
   ],
   "source": [
    "a = [i for i in range(1000*1000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, proceed with a simple reduction (sum):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 6.9 ms per loop\n",
      "In [3] used 0.066 MiB RAM in 2.879s, peaked 0.000 MiB above current, total RAM usage 63.055 MiB\n"
     ]
    }
   ],
   "source": [
    "t = %timeit -o sum(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which, in MIPS (Mega-Instructions-Per-Second) is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('MIPS:', 145.0)\n",
      "In [4] used -1.973 MiB RAM in 0.001s, peaked 0.000 MiB above current, total RAM usage 61.082 MiB\n"
     ]
    }
   ],
   "source": [
    "print(\"MIPS:\", round(1e6 / t.best / 1e6, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so that seems fast, but we don't have other references to compare with.  In addition, a list is not the best kind of container in terms of space consumption.  So let's try now a container that seems quite optimal in terms of memory savings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Containers using the array module in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [5] used 0.008 MiB RAM in 0.013s, peaked 0.000 MiB above current, total RAM usage 61.090 MiB\n"
     ]
    }
   ],
   "source": [
    "# Create an array of 'l'ong integers (8 bytes on 32-bit platforms)\n",
    "import array\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 76.36 MiB, increment: 15.26 MiB\n",
      "In [6] used 15.449 MiB RAM in 0.259s, peaked 0.000 MiB above current, total RAM usage 76.539 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit arr = array.array('l', a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.7 ~ 15 MB vs 31 MB seems like a good deal, although sometimes Python is allocating more memory than necessary.  In fact, the array module seems to provide optimal containers from a memory consumption point of view:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.19968"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [7] used 0.055 MiB RAM in 0.008s, peaked 0.000 MiB above current, total RAM usage 76.594 MiB\n"
     ]
    }
   ],
   "source": [
    "# Size per element:\n",
    "(mw.memory_delta * 2**20) / 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But how it performs during reductions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 11.5 ms per loop\n",
      "In [8] used 0.051 MiB RAM in 4.755s, peaked 0.000 MiB above current, total RAM usage 76.645 MiB\n"
     ]
    }
   ],
   "source": [
    "t = %timeit -o sum(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('MIPS:', 86.7)\n",
      "In [9] used 0.004 MiB RAM in 0.006s, peaked 0.000 MiB above current, total RAM usage 76.648 MiB\n"
     ]
    }
   ],
   "source": [
    "print(\"MIPS:\", round(1e6 / t.best / 1e6, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that's a bit disappointing, as the array object performs about 2x slower than a regular list.  Not sure about the resons, but probably the array module is not getting too much attention performance-wise mainly because the NumPy existance.  Speaking of NumPy: here we go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [10] used 6.621 MiB RAM in 0.041s, peaked 0.000 MiB above current, total RAM usage 83.270 MiB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [11] used 7.668 MiB RAM in 0.064s, peaked 0.000 MiB above current, total RAM usage 90.938 MiB\n"
     ]
    }
   ],
   "source": [
    "na = np.array(a, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that, with 8 bytes/element, NumPy is also an efficient container (much more than the `array` package in standard library which takes ~16 bytes/element)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 89 ms per loop\n",
      "In [12] used 0.020 MiB RAM in 3.651s, peaked 0.000 MiB above current, total RAM usage 90.957 MiB\n"
     ]
    }
   ],
   "source": [
    "t = %timeit -o sum(na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('MIPS:', 11.241)\n",
      "In [13] used 0.000 MiB RAM in 0.001s, peaked 0.000 MiB above current, total RAM usage 90.957 MiB\n"
     ]
    }
   ],
   "source": [
    "print(\"MIPS:\", round(1e6 / t.best / 1e6, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops, this is more than several times slower than the `array` module.  Why so?\n",
    "\n",
    "**Answer:** NumPy has a lot of overhead in producing a Python integer for every element in the array.\n",
    "\n",
    "*Hint:* Use internal methods (ufuncs) when possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 3: 551 Âµs per loop\n",
      "In [14] used 0.121 MiB RAM in 2.285s, peaked 0.000 MiB above current, total RAM usage 91.078 MiB\n"
     ]
    }
   ],
   "source": [
    "t = %timeit -o na.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('MIPS:', 1814.714)\n",
      "In [15] used 0.008 MiB RAM in 0.001s, peaked 0.000 MiB above current, total RAM usage 91.086 MiB\n"
     ]
    }
   ],
   "source": [
    "print(\"MIPS:\", round(1e6 / t.best / 1e6, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is about 100x the speed of sum() on a Python list and it is also pretty optimal in terms of both execution time and space consumed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "The speed in the above reduction is limited by memory speed, not CPU speed.  Could you provide a hint on the maximum memory speed that supports your laptop?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using compressed in-memory containers with bcolz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But let us suppose that we have really big data to process in our laptop and want to see if we can store our data in less space.  Enter compression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [16] used 22.207 MiB RAM in 0.174s, peaked 0.000 MiB above current, total RAM usage 113.293 MiB\n"
     ]
    }
   ],
   "source": [
    "import bcolz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [17] used 0.691 MiB RAM in 0.005s, peaked 0.000 MiB above current, total RAM usage 113.984 MiB\n"
     ]
    }
   ],
   "source": [
    "ca = bcolz.carray(na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('mem_used:', 0.69140625)\n",
      "In [18] used 0.020 MiB RAM in 0.007s, peaked 0.000 MiB above current, total RAM usage 114.004 MiB\n"
     ]
    }
   ],
   "source": [
    "print(\"mem_used:\", mw.measurements.memory_delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, this time the amount of memory used seems much lower.  Also, bcolz containers can provide an estimation on how much memory they are taking; let's have a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "carray((1000000,), int64)\n",
       "  nbytes: 7.63 MB; cbytes: 394.28 KB; ratio: 19.81\n",
       "  cparams := cparams(clevel=5, shuffle=True, cname='blosclz')\n",
       "[     0      1      2 ..., 999997 999998 999999]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [19] used 0.066 MiB RAM in 0.008s, peaked 0.000 MiB above current, total RAM usage 114.070 MiB\n"
     ]
    }
   ],
   "source": [
    "ca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we see that bcolz estimation is reasonably close to `ipython_memwatcher` measurements.  Let's have a look at the speed of the reduction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 1.87 ms per loop\n",
      "('MIPS:', 533.584)\n",
      "In [20] used 0.078 MiB RAM in 0.838s, peaked 0.000 MiB above current, total RAM usage 114.148 MiB\n"
     ]
    }
   ],
   "source": [
    "t = %timeit -o ca.sum()\n",
    "print(\"MIPS:\", round(1e6 / t.best / 1e6, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is around 2~4x slower (depending on the machine) than a regular NumPy array, but the size of the array is an impressive 10x smaller.  But is compression the only responsible of the overhead?  Let's investigate a bit further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using uncompressed containers with bcolz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In order to see if this is because of the compression overhead, let's use an uncompressed array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [21] used 14.859 MiB RAM in 0.056s, peaked 0.000 MiB above current, total RAM usage 129.008 MiB\n"
     ]
    }
   ],
   "source": [
    "cau = bcolz.carray(a, cparams=bcolz.cparams(clevel=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "carray((1000000,), int64)\n",
       "  nbytes: 7.63 MB; cbytes: 7.75 MB; ratio: 0.98\n",
       "  cparams := cparams(clevel=0, shuffle=True, cname='blosclz')\n",
       "[     0      1      2 ..., 999997 999998 999999]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [22] used 0.008 MiB RAM in 0.008s, peaked 0.000 MiB above current, total RAM usage 129.016 MiB\n"
     ]
    }
   ],
   "source": [
    "cau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 3: 1.93 ms per loop\n",
      "('MIPS:', 517.007)\n",
      "In [23] used 0.012 MiB RAM in 8.307s, peaked 0.000 MiB above current, total RAM usage 129.027 MiB\n"
     ]
    }
   ],
   "source": [
    "t = %timeit -o cau.sum()\n",
    "print(\"MIPS:\", round(1e6 / t.best / 1e6, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the times with an uncompressed `carray` are very close to a compressed one, so compressing is not the only source of the overhead (and it is very minor in fact).  The actual source of the difference is the memory layout of the different containers (bcolz layout is a bit more complex than NumPy).\n",
    "\n",
    "So, bcolz allows to use compressed in-memory data containers at the cost of some performance (compared with NumPy).  But the performance overhead is rather small, and sometimes you prefer to keep more data in-memory.\n",
    "\n",
    "On another hand, in the next notebooks we are going to see that bcolz can be competitive with NumPy, performance wise, in some scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Using bcolz in real scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bcolz does not get good compression ratios only with synthetic data, but with real data too.  Be sure to check out this URL:\n",
    "\n",
    "http://nbviewer.ipython.org/gist/alimanfoo/e93a532eb6bde311ea39/genotype_bitshuffle.ipynb\n",
    "\n",
    "and let's discuss this specific case of bcolz usage in genomics:\n",
    "\n",
    "* Which are the typical compression ratios for this case?\n",
    "\n",
    "* Is there a difference in speed accessing data in compressed and non-compressed state (clevel=0)\n",
    "\n",
    "* Which are the compressors achieving the best compression/speed ratio?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
