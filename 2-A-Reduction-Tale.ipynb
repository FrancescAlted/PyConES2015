{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Reduction Tale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Objectives:\n",
    "> * Compare operations taking place in different data containers\n",
    "> * Compare sizes for these data containers\n",
    "> * Help deciding when it is best to use a container or another"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's suppose that we are going to need reductions a lot and we want to choose the best container for performing them.  First, let's start by activating our MemWatcher agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [1] used 0.020 MiB RAM in 0.001s, peaked 0.000 MiB above current, total RAM usage 31.672 MiB\n"
     ]
    }
   ],
   "source": [
    "from ipython_memwatcher import MemWatcher\n",
    "mw = MemWatcher()\n",
    "mw.start_watching_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and choose a different container for the data that we want to reduce, starting with a list:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [2] used 31.137 MiB RAM in 0.126s, peaked 0.000 MiB above current, total RAM usage 62.809 MiB\n"
     ]
    }
   ],
   "source": [
    "a = [i for i in range(1000*1000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, proceed with a simple reduction (sum):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 6.91 ms per loop\n",
      "In [3] used 0.039 MiB RAM in 2.923s, peaked 0.000 MiB above current, total RAM usage 62.848 MiB\n"
     ]
    }
   ],
   "source": [
    "t = %timeit -o sum(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which, in MIPS (Mega-Instructions-Per-Second) is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('MIPS:', 144.8)\n",
      "In [4] used 0.012 MiB RAM in 0.002s, peaked 0.000 MiB above current, total RAM usage 62.859 MiB\n"
     ]
    }
   ],
   "source": [
    "print(\"MIPS:\", round(1e6 / t.best / 1e6, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so that seems fast, but we don't have other references to compare with.  In addition, a list is not the best kind of container in terms of space consumption.  So let's try now a container that seems quite optimal in terms of memory savings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Containers using the array module in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [5] used 0.004 MiB RAM in 0.004s, peaked 0.000 MiB above current, total RAM usage 62.863 MiB\n"
     ]
    }
   ],
   "source": [
    "# Create an array of 'l'ong integers (8 bytes on 32-bit platforms)\n",
    "import array\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 78.20 MiB, increment: 15.32 MiB\n",
      "In [6] used 15.488 MiB RAM in 0.417s, peaked 0.000 MiB above current, total RAM usage 78.352 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit arr = array.array('l', a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.7 ~ 15 MB vs 31 MB seems like a good deal, although sometimes Python is allocating more memory than necessary.  In fact, the array module seems to provide optimal containers from a memory consumption point of view:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.24064"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [7] used 0.031 MiB RAM in 0.026s, peaked 0.000 MiB above current, total RAM usage 78.383 MiB\n"
     ]
    }
   ],
   "source": [
    "# Size per element:\n",
    "(mw.memory_delta * 2**20) / 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But how it performs during reductions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 11.5 ms per loop\n",
      "In [8] used 0.016 MiB RAM in 4.819s, peaked 0.000 MiB above current, total RAM usage 78.398 MiB\n"
     ]
    }
   ],
   "source": [
    "t = %timeit -o sum(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('MIPS:', 86.7)\n",
      "In [9] used 0.000 MiB RAM in 0.002s, peaked 0.000 MiB above current, total RAM usage 78.398 MiB\n"
     ]
    }
   ],
   "source": [
    "print(\"MIPS:\", round(1e6 / t.best / 1e6, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that's a bit disappointing, as the array object performs about 2x slower than a regular array.  Not sure about the resons, but probably the array module is not getting too much attention performance-wise mainly because the NumPy existance.  Speaking of NumPy: here we go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [10] used 6.680 MiB RAM in 0.491s, peaked 0.000 MiB above current, total RAM usage 85.078 MiB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [11] used 7.645 MiB RAM in 0.109s, peaked 0.000 MiB above current, total RAM usage 92.723 MiB\n"
     ]
    }
   ],
   "source": [
    "na = np.array(a, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that, with 8 bytes/element, NumPy is also an efficient container (much more than the `array` package in standard library which takes ~16 bytes/element)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 87.9 ms per loop\n",
      "In [12] used 0.016 MiB RAM in 3.713s, peaked 0.000 MiB above current, total RAM usage 92.738 MiB\n"
     ]
    }
   ],
   "source": [
    "t = %timeit -o sum(na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('MIPS:', 11.381)\n",
      "In [13] used 0.004 MiB RAM in 0.003s, peaked 0.000 MiB above current, total RAM usage 92.742 MiB\n"
     ]
    }
   ],
   "source": [
    "print(\"MIPS:\", round(1e6 / t.best / 1e6, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops, this is more than several times slower than the `array` module.  Why so?\n",
    "\n",
    "**Answer:** NumPy has a lot of overhead in producing a Python integer for every element in the array.\n",
    "\n",
    "*Hint:* Use internal methods (ufuncs) when possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 4.67 times longer than the fastest. This could mean that an intermediate result is being cached \n",
      "1000 loops, best of 3: 551 Âµs per loop\n",
      "In [14] used 0.125 MiB RAM in 2.438s, peaked 0.000 MiB above current, total RAM usage 92.867 MiB\n"
     ]
    }
   ],
   "source": [
    "t = %timeit -o na.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('MIPS:', 1814.092)\n",
      "In [15] used 0.004 MiB RAM in 0.003s, peaked 0.000 MiB above current, total RAM usage 92.871 MiB\n"
     ]
    }
   ],
   "source": [
    "print(\"MIPS:\", round(1e6 / t.best / 1e6, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is about 100x the speed of sum() on a Python list and it is also pretty optimal in terms of both execution time and space consumed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "The speed in the above reduction is limited by memory speed, not CPU speed.  Could you provide a hint on the maximum memory speed that supports your laptop?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using compressed in-memory containers with bcolz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But let us suppose that we have really big data to process in our laptop and want to see if we can store our data in less space.  Enter compression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [16] used 22.215 MiB RAM in 1.208s, peaked 0.000 MiB above current, total RAM usage 115.086 MiB\n"
     ]
    }
   ],
   "source": [
    "import bcolz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [17] used 0.652 MiB RAM in 0.009s, peaked 0.000 MiB above current, total RAM usage 115.738 MiB\n"
     ]
    }
   ],
   "source": [
    "ca = bcolz.carray(na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('mem_used:', 0.65234375)\n",
      "In [18] used 0.016 MiB RAM in 0.002s, peaked 0.000 MiB above current, total RAM usage 115.754 MiB\n"
     ]
    }
   ],
   "source": [
    "print(\"mem_used:\", mw.measurements.memory_delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, this time the amount of memory used seems much lower.  Also, bcolz containers can provide an estimation on how much memory they are taking; let's have a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "carray((1000000,), int64)\n",
       "  nbytes: 7.63 MB; cbytes: 394.28 KB; ratio: 19.81\n",
       "  cparams := cparams(clevel=5, shuffle=True, cname='blosclz')\n",
       "[     0      1      2 ..., 999997 999998 999999]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [19] used 0.078 MiB RAM in 0.006s, peaked 0.000 MiB above current, total RAM usage 115.832 MiB\n"
     ]
    }
   ],
   "source": [
    "ca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we see that bcolz estimation is reasonably close to `ipython_memwatcher` measurements.  Let's have a look at the speed of the reduction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 1.86 ms per loop\n",
      "('MIPS:', 537.429)\n",
      "In [20] used 0.059 MiB RAM in 1.041s, peaked 0.000 MiB above current, total RAM usage 115.891 MiB\n"
     ]
    }
   ],
   "source": [
    "t = %timeit -o ca.sum()\n",
    "print(\"MIPS:\", round(1e6 / t.best / 1e6, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is around 2~4x slower (depending on the machine) than a regular NumPy array, but the size of the array is an impressive 20x smaller.  But is compression the only responsible of the overhead?  Let's investigate a bit further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using uncompressed containers with bcolz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In order to see if this is because of the compression overhead, let's use an uncompressed array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [21] used 14.785 MiB RAM in 0.104s, peaked 0.000 MiB above current, total RAM usage 130.676 MiB\n"
     ]
    }
   ],
   "source": [
    "cau = bcolz.carray(a, cparams=bcolz.cparams(clevel=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "carray((1000000,), int64)\n",
       "  nbytes: 7.63 MB; cbytes: 7.75 MB; ratio: 0.98\n",
       "  cparams := cparams(clevel=0, shuffle=True, cname='blosclz')\n",
       "[     0      1      2 ..., 999997 999998 999999]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [22] used 0.008 MiB RAM in 0.006s, peaked 0.000 MiB above current, total RAM usage 130.684 MiB\n"
     ]
    }
   ],
   "source": [
    "cau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 1.9 ms per loop\n",
      "('MIPS:', 527.535)\n",
      "In [23] used 0.008 MiB RAM in 0.890s, peaked 0.000 MiB above current, total RAM usage 130.691 MiB\n"
     ]
    }
   ],
   "source": [
    "t = %timeit -o cau.sum()\n",
    "print(\"MIPS:\", round(1e6 / t.best / 1e6, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the times with an uncompressed `carray` are very close to a compressed one, so compressing is not the only source of the overhead (and it is very minor in fact).\n",
    "\n",
    "So, bcolz allows to use compressed in-memory data containers at the cost of some performance (compared with NumPy).  But the performance overhead is rather small, and sometimes you prefer to keep more data in-memory.\n",
    "\n",
    "On another hand, in the next notebooks we are going to see that bcolz can be competitive with NumPy, performance wise, in some scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Using bcolz in real scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bcolz does not get good compression ratios only with synthetic data, but with real data too.  Be sure to check out this URL:\n",
    "\n",
    "http://nbviewer.ipython.org/gist/alimanfoo/e93a532eb6bde311ea39/genotype_bitshuffle.ipynb\n",
    "\n",
    "and let's discuss this specific case of bcolz usage in genomics:\n",
    "\n",
    "* Which are the typical compression ratios for this case?\n",
    "\n",
    "* Is there a difference in speed accessing data in compressed and non-compressed state (clevel=0)\n",
    "\n",
    "* Which are the compressors achieving the best compression/speed ratio?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
